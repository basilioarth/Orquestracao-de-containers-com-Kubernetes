# Resumo da Aula sobre Configuração de Deployment no Kubernetes e Introdução a Conceitos de Segurança

## Introdução
A aula apresenta o objeto **Deployment**, que gerencia **ReplicaSets** e resolve limitações do **ReplicaSet** em atualizações de versão, garantindo mudanças sem **downtime** por meio de estratégias como **Rolling Update**. O arquivo `replica-set.yaml` é convertido em `deployment.yaml`, configurando um **Deployment** para a aplicação `widget-server`. A aula também aborda problemas de observabilidade (ex.: logs descentralizados por pod), a natureza **stateless** da aplicação, e a necessidade de expor múltiplas réplicas para clientes, sugerindo o uso de um **Service** (a ser abordado posteriormente). Por fim, introduz conceitos de segurança e sondagem para monitoramento, que serão explorados na próxima aula.

## Configuração do Deployment
- **Contexto**:
  - O **ReplicaSet** garante réplicas, mas não suporta atualizações de versão sem **downtime** (ex.: troca de `v3` para `v2`). O **Deployment** é apresentado como um controlador superior, gerenciando ReplicaSets e permitindo atualizações contínuas.
  - A hierarquia do Kubernetes é reforçada: **Pod** (menor unidade), **ReplicaSet** (controla réplicas), **Deployment** (gerencia ReplicaSets e atualizações).
- **Modificações no Arquivo YAML**:
  - O arquivo `replica-set.yaml` é renomeado para `deployment.yaml` e ajustado:
    ```yaml
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: widget-server
      namespace: widget
    spec:
      replicas: 5
      selector:
        matchLabels:
          app: widget-server
      strategy:
        type: RollingUpdate
        rollingUpdate:
          maxSurge: 20%
          maxUnavailable: 10%
      template:
        metadata:
          labels:
            app: widget-server
        spec:
          containers:
          - name: widget-server
            image: danielrodrigues/widget-server:v3
            ports:
            - containerPort: 3333
            env:
            - name: SECRET_ACCESS
              value: "#<secret_access_value>"
            - name: BUCKET
              value: "#<bucket_value>"
            - name: ACCOUNT_ID
              value: "#<account_id_value>"
            - name: PUBLIC_URL
              value: "#<public_url_value>"
            - name: LOCALHOST
              value: "http://localhost:3333"
            resources:
              requests:
                cpu: "200m"
                memory: "256Mi"
              limits:
                cpu: "300m"
                memory: "384Mi"
    ```
  - **Mudanças Realizadas**:
    - **`apiVersion`**: Mantido como `apps/v1`, igual ao ReplicaSet.
    - **`kind`**: Alterado de `ReplicaSet` para `Deployment`.
    - **`metadata.name`**: Renomeado para `widget-server` (em vez de `widget-server-rs`).
    - **`spec.strategy`**: Adicionado para definir a estratégia de atualização:
      - `type: RollingUpdate`: Estratégia padrão, que atualiza pods gradualmente, sem **downtime**.
      - `rollingUpdate`:
        - `maxSurge: 20%`: Permite até 20% de pods adicionais (ex.: 1 pod extra para 5 réplicas) durante a atualização.
        - `maxUnavailable: 10%`: Limita a indisponibilidade a 10% dos pods (ex.: no máximo 1 pod indisponível).
    - O restante (`replicas`, `selector`, `template`) é idêntico ao `replica-set.yaml`.
- **Funcionamento do Deployment**:
  - O **Deployment** cria um **ReplicaSet** para gerenciar os pods. Cada pod tem um nome baseado no Deployment (ex.: `widget-server-abc123`).
  - O `selector.matchLabels` associa o Deployment aos pods com a label `app: widget-server`.
  - A estratégia **RollingUpdate** atualiza pods sequencialmente: remove um pod antigo, cria um novo com a nova versão, e repete até completar todas as réplicas.

## Aplicação e Validação
- **Deleção do ReplicaSet Anterior**:
  - **Comando**: `kubectl delete rs widget-server-rs -n widget`
    - Remove o ReplicaSet anterior e seus pods.
  - **Comando**: `kubectl get pods -n widget` e `kubectl get rs -n widget`
    - Confirma que não há mais pods ou ReplicaSets no namespace `widget`.
- **Criação do Deployment**:
  - **Comando**: `kubectl apply -f k8s/deployment.yaml`
    - Cria o Deployment `widget-server` e um novo ReplicaSet associado.
  - **Comando**: `kubectl get deployment -n widget`
    - Mostra o Deployment com 5 réplicas desejadas, 5 em execução e 5 prontas.
  - **Comando**: `kubectl get rs -n widget`
    - Revela o ReplicaSet criado pelo Deployment (ex.: `widget-server-xyz123`).
  - **Comando**: `kubectl get pods -n widget`
    - Lista os 5 pods gerados, com nomes como `widget-server-xyz123-8bxtq`.
- **Teste de Atualização de Versão**:
  - Alteração no `deployment.yaml`: Troca a imagem de `danielrodrigues/widget-server:v3` para `v2` e aplicação com `kubectl apply`.
    - **Resultado com `Recreate`**: 
      - Configurado temporariamente com `strategy.type: Recreate`.
      - Todos os pods são deletados antes de criar novos com `v2`, causando **downtime**.
      - Logs (`kubectl logs`) confirmam que `v2` apresenta problemas, como esperado.
    - **Correção**: Reverte para `v3` e muda para `strategy.type: RollingUpdate`.
      - **Comando**: `kubectl apply -f k8s/deployment.yaml` com `watch kubectl get pods -n widget`
      - A atualização ocorre gradualmente: um pod antigo é removido, um novo com `v3` é criado, e o processo se repete, sem **downtime**.
      - O `maxSurge: 20%` permite até 6 pods (5 + 1) durante a transição, e `maxUnavailable: 10%` garante pelo menos 4 pods disponíveis.
- **Teste de Resiliência**:
  - **Comando**: `kubectl delete pod widget-server-xyz123-8bxtq -n widget`
    - Deleta um pod específico.
    - O ReplicaSet gerenciado pelo Deployment cria um novo pod automaticamente, mantendo 5 réplicas.
  - **Comando**: `watch kubectl get pods -n widget`
    - Mostra a recriação do pod, confirmando o **loop de reconciliação** do Kubernetes.

## Limitações e Observações
- **Observabilidade**:
  - Cada pod tem seus próprios logs, acessíveis via `kubectl logs <pod-name> -n widget`.
    - Exemplo: Um pod (`widget-server-xyz123-8bxtq`) mostra logs da aplicação, enquanto outro (`widget-server-xyz123-9pws8`) pode não ter logs de requisições, indicando descentralização.
  - **Problema**: Logs distribuídos dificultam o monitoramento. Um sistema centralizado de observabilidade (ex.: ELK, Fluentd) é necessário para agregar logs e métricas.
- **Acesso à Aplicação**:
  - Cada pod tem um IP único e dinâmico (ex.: `10.244.2.7`), o que torna o `kubectl port-forward` inviável para múltiplas réplicas.
  - **Solução Futura**: Um objeto **Service** será necessário para expor as réplicas com balanceamento de carga, garantindo um ponto de acesso único para clientes.
  - Tentativas de `port-forward` para o ReplicaSet ou Deployment não são práticas, pois as requisições precisam ser distribuídas entre os pods.
- **Natureza Stateless**:
  - A aplicação `widget-server` é **stateless**, sem estado persistente, adequada para pods descartáveis.
  - Se for necessário estado (ex.: banco de dados), volumes persistentes serão configurados em aulas futuras.
- **Estratégias de Deploy**:
  - **Recreate**: Deleta todos os pods antes de criar novos, causando **downtime**. Adequado para jobs não críticos, mas não para serviços voltados a clientes.
  - **Rolling Update** (padrão): Atualiza pods gradualmente, sem **downtime**, ideal para aplicações em produção.
  - **Blue-Green**: Mantém duas versões (antiga e nova) simultaneamente, redirecionando tráfego após validação. Não é nativo do Kubernetes, mas pode ser implementado.
  - **Canary**: Direciona uma porcentagem do tráfego (ex.: 10%) para a nova versão, permitindo testes graduais. Também não é nativo, mas pode ser configurado com ferramentas adicionais.
- **Match Labels vs. Match Expressions**:
  - O `selector.matchLabels` usa labels simples (ex.: `app: widget-server`) para associar o Deployment aos pods.
  - **Match Expressions** permitem seletores mais complexos, mas não foram necessários neste caso.
  - Erro de configuração: Se `matchLabels` não corresponder às labels do `template`, o Deployment falha, como testado com uma label inválida (`app: universo`).

## Conceitos de Segurança (Introdução)
- **Mecanismos de Sondagem**:
  - O Kubernetes tenta reiniciar pods em caso de falhas (ex.: **CrashLoopBackOff**), mas isso nem sempre resolve problemas.
  - **Sondas** (probes) serão abordadas na próxima aula para monitorar a saúde dos pods (ex.: liveness, readiness) e tomar ações proativas.
- **Importância**:
  - Garantir que a aplicação está funcionando corretamente.
  - Detectar problemas antes que impactem usuários.
  - Evitar reinícios desnecessários com monitoramento adequado.

## Próximos Passos
- **Sondas de Saúde**:
  - Configurar **livenessProbe** e **readinessProbe** para verificar a saúde dos pods e evitar falhas não detectadas.
- **Service**:
  - Resolver o problema de exposição de múltiplos pods com IPs dinâmicos, usando um **Service** para balanceamento de carga.
- **Volumes Persistentes**:
  - Explorar configurações para aplicações **stateful**, se necessário.
- **Blue-Green e Canary Deployments**:
  - Implementar estratégias avançadas, possivelmente com ferramentas complementares ao Kubernetes.

## Conclusão
A aula converte o `replica-set.yaml` em `deployment.yaml`, configurando um **Deployment** para gerenciar cinco réplicas do `widget-server` com a estratégia **Rolling Update**, que evita **downtime** durante atualizações (ex.: troca de `v2` para `v3`). O Deployment cria ReplicaSets automaticamente, garantindo resiliência e escalabilidade. Problemas como logs descentralizados e acesso a múltiplos pods destacam a necessidade de um **Service** e sistemas de observabilidade. A natureza **stateless** da aplicação é reforçada, e a introdução de sondas de saúde é preparada para a próxima aula, visando melhorar a segurança e monitoramento do sistema.
# Resumo da Aula sobre Configuração do Horizontal Pod Autoscaler (HPA) com API `autoscaling/v2` no Kubernetes

## Introdução
A aula dá continuidade à configuração do **Horizontal Pod Autoscaler (HPA)** para a aplicação `widget-server`, migrando da API legada (`autoscaling/v1`) para a API moderna (`autoscaling/v2`). A nova API oferece maior flexibilidade, permitindo escalabilidade baseada em CPU, memória e métricas customizadas. A aula também esclarece a relação do **KEDA** com o HPA, destacando que o **KEDA** usa o HPA para escalas baseadas em eventos, substituindo o **Metrics Server** em arquiteturas orientadas a eventos (EDA). A configuração é testada, simulando um cenário de escalabilidade ao ajustar a métrica de memória, e introduz o conceito de janelas de estabilização (`behavior`) para controle de escalas.

## Configuração Inicial e Remoção do HPA Antigo
- **Contexto**:
  - A API `autoscaling/v1` foi usada na aula anterior para criar o HPA `widget-server-hpa`, escalando o **Deployment** `widget-server` com base em CPU (alvo: 75%, mínimo: 3 réplicas, máximo: 8).
  - A API `autoscaling/v2` será agora utilizada para suportar CPU e memória, com maior personalização.
- **Remoção do HPA Antigo**:
  - **Comando**: `kubectl delete -f k8s/hpa.yaml`
    - Remove o HPA `widget-server-hpa` do namespace `widget`.
  - **Verificação**: `kubectl get hpa -n widget`
    - Confirma que não há mais HPAs no namespace.
- **Objetivo**: Atualizar o arquivo `hpa.yaml` para usar a API `autoscaling/v2`, mantendo o mesmo arquivo para evitar duplicação.

## Atualização do Arquivo `hpa.yaml` com `autoscaling/v2`
- **Motivação**:
  - A API `autoscaling/v2` é mais moderna, suportando múltiplas métricas (CPU, memória, customizadas) e configurações avançadas, como comportamento de escalabilidade.
  - A API `autoscaling/v1` é limitada a CPU e ainda comum em clusters legados, mas menos flexível.
- **Novo Arquivo `hpa.yaml`**:
  ```yaml
  apiVersion: autoscaling/v2
  kind: HorizontalPodAutoscaler
  metadata:
    name: widget-server-hpa
    namespace: widget
  spec:
    scaleTargetRef:
      apiVersion: apps/v1
      kind: Deployment
      name: widget-server
    minReplicas: 3
    maxReplicas: 8
    metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 75
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: 70
  ```
- **Detalhes**:
  - **`apiVersion: autoscaling/v2`**: Usa a API moderna, permitindo múltiplas métricas.
  - **`kind` e `metadata`**: Mantêm o mesmo tipo (`HorizontalPodAutoscaler`) e nome (`widget-server-hpa`) no namespace `widget`.
  - **`spec.scaleTargetRef`**: Referencia o **Deployment** `widget-server` (API `apps/v1`), igual à versão anterior.
  - **`spec.minReplicas: 3` e `maxReplicas: 8`**: Mantêm os limites de 3 a 8 réplicas.
  - **`spec.metrics`**: Nova estrutura que substitui `targetCPUUtilizationPercentage` da API `v1`.
    - **Métrica 1: CPU**:
      - `type: Resource`: Especifica métrica de recurso computacional.
      - `resource.name: cpu`: Alvo é o uso de CPU.
      - `target.type: Utilization`: Usa a média de utilização (em relação ao `requests` do pod).
      - `target.averageUtilization: 75`: Escala se o uso médio de CPU ultrapassar 75% (150m para 200m configurados por pod).
    - **Métrica 2: Memória**:
      - `type: Resource`: Recurso computacional.
      - `resource.name: memory`: Alvo é o uso de memória.
      - `target.type: Utilization`: Média de utilização.
      - `target.averageUtilization: 70`: Escala se o uso médio de memória ultrapassar 70% (179.2Mi para 256Mi configurados por pod).
- **Aplicação**: `kubectl apply -f k8s/`
  - Cria o novo HPA com métricas de CPU e memória.
- **Verificação**: `kubectl get hpa -n widget`
  - Exibe o HPA `widget-server-hpa`:
    - **Referência**: `Deployment/widget-server`.
    - **Mínimo/Máximo**: 3/8 réplicas.
    - **Uso Atual**:
      - CPU: Inicialmente `unknown`, depois sincronizado (ex.: 0% sem tráfego).
      - Memória: Ex.: 26% (66.56Mi de 256Mi por pod, sem tráfego).
    - **Alvos**: 75% (CPU), 70% (memória).

## Teste de Escalabilidade
- **Simulação de Pico**:
  - Para demonstrar o funcionamento do HPA, o `averageUtilization` de memória foi temporariamente alterado para 20% (abaixo do uso atual de 26%).
  - **Comando**: `kubectl apply -f k8s/`
    - Aplica a mudança no `hpa.yaml`.
  - **Resultado**:
    - O HPA detecta que o uso de memória (26%) excede o alvo (20%) e escala automaticamente.
    - **Verificação**: `kubectl get pods -n widget`
      - Mostra o aumento de réplicas (ex.: de 3 para 4, 6, até 7 pods em poucos minutos).
    - **Comando**: `kubectl get hpa -n widget`
      - Confirma que o uso de memória está acima do alvo (ex.: 26% > 20%), desencadeando a criação de réplicas.
      - Após a escalabilidade, o uso de memória por pod diminui (ex.: para 25%), pois a carga é distribuída entre mais réplicas.
  - **Detalhes do Processo**:
    - O HPA escala rapidamente para cima (scale up) devido ao uso de memória acima do alvo.
    - **Comando**: `kubectl describe hpa -n widget`
      - Mostra eventos do HPA, confirmando a criação de réplicas automáticas.
    - O número de réplicas aumenta até 7 (próximo do limite máximo de 8), aliviando a carga de memória.

- **Retorno ao Estado Normal**:
  - O `averageUtilization` de memória é ajustado de volta para 70% (acima do uso atual de 26%).
  - **Comando**: `kubectl apply -f k8s/`
    - Aplica a correção no `hpa.yaml`.
  - **Resultado**:
    - O HPA detecta que o uso de memória (ex.: 25%) está abaixo do alvo (70%) e inicia o **downscaling**.
    - **Verificação**: `kubectl get pods -n widget`
      - Mostra a redução de réplicas (ex.: de 7 para 3, o mínimo configurado).
    - O **downscaling** é mais lento que o **scale up**, pois o HPA adota uma abordagem cautelosa para evitar interrupções abruptas.
  - **Motivação**:
    - Réplicas excedentes consomem recursos desnecessariamente, aumentando custos.
    - O **downscaling** automático otimiza o uso do cluster, retornando ao mínimo de réplicas (3) quando o uso de CPU e memória está abaixo dos alvos.

## Janelas de Estabilização (Behavior)
- **Conceito**:
  - O HPA possui janelas de estabilização (`behavior`) que controlam a velocidade de **scale up** (aumento de réplicas) e **scale down** (redução de réplicas).
  - **Scale Up**: Rápido para garantir resposta a picos de tráfego.
  - **Scale Down**: Mais lento para evitar interrupções, já que remover réplicas abruptamente pode causar falhas se a carga aumentar novamente.
- **Observação**:
  - No teste, o **scale up** foi ágil (ex.: de 3 para 7 réplicas em minutos), enquanto o **scale down** foi gradual (ex.: de 7 para 3 réplicas ao longo de mais tempo).
  - A API `autoscaling/v2` permite configurar o comportamento:
    - Ex.: Definir quantos pods criar/remover por período (ex.: 2 pods a cada 30 segundos).
    - Ajustar a velocidade de **scale up** (mais rápido/lento) ou **scale down** (mais rápido/lento).
- **Próxima Aula**:
  - Explorar a configuração do `behavior` no `hpa.yaml` para personalizar as janelas de estabilização.

## Esclarecimentos sobre KEDA
- **Relação com o HPA**:
  - O **KEDA** (Kubernetes Event-Driven Autoscaling) não substitui o HPA, mas o utiliza como mecanismo de escalabilidade.
  - Substitui o **Metrics Server** em arquiteturas orientadas a eventos (EDA), como aplicações que consomem filas (ex.: Kafka, RabbitMQ).
  - **Funcionamento**:
    - O **KEDA** monitora eventos (ex.: throughput de mensagens em uma fila) e instrui o HPA a escalar com base nessas métricas.
    - Exemplo: Escalar réplicas com base no número de mensagens não processadas no Kafka, em vez de CPU/memória.
  - **Vantagem**: Ideal para aplicações onde o uso de CPU/memória não reflete a carga real (ex.: processamento de eventos).
- **Nota**: O **KEDA** não será abordado em detalhes, mas é mencionado como uma alternativa para cenários de EDA.

## Planejamento para a Próxima Aula
- **Configuração Avançada do HPA**:
  - Explorar o campo `behavior` no `hpa.yaml` para personalizar:
    - Velocidade de **scale up** e **scale down**.
    - Quantidade de réplicas adicionadas/removidas por período.
  - Testar métricas customizadas (ex.: throughput de eventos), embora com menor foco.
- **Testes de Estresse**:
  - Estressar a aplicação `widget-server` para validar o comportamento do HPA em cenários reais.
  - Ex.: Simular tráfego intenso para disparar escalas automáticas baseadas em CPU e memória.
- **Refinamento do "Chutômetro"**:
  - Usar testes de estresse para determinar valores mais precisos para `minReplicas`, `maxReplicas`, e alvos de utilização (CPU/memória).
- **Outros Tópicos**:
  - Continuar a explorar **Secrets** e **Ingress** para a aplicação.
  - Integrar ferramentas de observabilidade (ex.: Prometheus, Grafana) para monitorar o HPA e a aplicação.

## Limitações e Observações
- **API `autoscaling/v2`**:
  - Mais flexível que `autoscaling/v1`, suportando CPU, memória e métricas customizadas.
  - Requer o **Metrics Server** para métricas de CPU/memória; métricas customizadas podem exigir ferramentas adicionais (ex.: Prometheus Adapter).
- **Janelas de Estabilização**:
  - O **scale down** lento é intencional para evitar interrupções, mas pode ser ajustado via `behavior`.
  - Configurações inadequadas (ex.: alvos muito baixos, como 20% para memória) podem causar escalas desnecessárias, aumentando custos.
- **KEDA**:
  - Ideal para arquiteturas orientadas a eventos, mas requer configuração adicional (CRDs e escaladores específicos).
  - Complementa o HPA, não o substitui.
- **Testes de Estresse**:
  - Essenciais para calibrar o HPA e evitar configurações baseadas em suposições.
  - Ajudam a determinar limites realistas para réplicas e alvos de utilização.
- **Custo e Otimização**:
  - Réplicas excedentes consomem recursos, aumentando custos em clusters pagos.
  - O **downscaling** automático do HPA é crucial para eficiência.
- **Ambiente Local**:
  - A configuração do **Metrics Server** com `--kubelet-insecure-tls` é aceitável para aprendizado, mas não para produção.
- **Boas Práticas**:
  - Definir alvos de utilização entre 70-80% para CPU/memória para evitar escalas tardias.
  - Monitorar o `maxReplicas` para detectar anomalias (ex.: atingir o limite máximo indica problemas).
  - Usar testes de estresse para refinar configurações iniciais do **Deployment** e HPA.

## Conclusão
A aula migra o HPA da API `autoscaling/v1` para `autoscaling/v2`, configurando o `hpa.yaml` para escalar o **Deployment** `widget-server` com base em CPU (75%) e memória (70%), com 3 a 8 réplicas. O teste com um alvo de memória de 20% demonstra a escalabilidade automática (de 3 para 7 réplicas) e o **downscaling** ao retornar para 70%. A API `v2` oferece maior personalização, incluindo suporte a múltiplas métricas e configurações de comportamento (`behavior`), que serão exploradas na próxima aula. O esclarecimento sobre o **KEDA** destaca sua integração com o HPA para arquiteturas orientadas a eventos. A aula reforça a importância de testes de estresse e monitoramento para otimizar configurações, garantindo eficiência e resiliência no cluster.
# Resumo da Aula sobre Configuração Avançada do Horizontal Pod Autoscaler (HPA) com Behavior no Kubernetes

## Introdução
A aula conclui a configuração do **Horizontal Pod Autoscaler (HPA)** para a aplicação `widget-server`, focando na personalização do comportamento (`behavior`) na API `autoscaling/v2`. A nova configuração ajusta as janelas de estabilização para **scale up** e **scale down**, controlando a velocidade e a agressividade das escalas. Um teste prático é realizado, reduzindo temporariamente o alvo de memória para simular um pico de uso, demonstrando a eficácia das configurações de `behavior`. A aula também reforça a flexibilidade do HPA em monitorar CPU e/ou memória e prepara o cenário para testes de estresse na próxima aula.

## Configuração Inicial
- **Contexto**:
  - O HPA `widget-server-hpa` foi configurado na aula anterior com a API `autoscaling/v2`, escalando o **Deployment** `widget-server` com base em CPU (75%) e memória (70%), com 3 a 8 réplicas.
  - A aula anterior testou a escalabilidade ajustando o alvo de memória para 20%, observando o **scale up** (de 3 para 7 réplicas) e o **downscaling** (de volta para 3).
  - O **downscaling** foi inicialmente lento (padrão de 300 segundos), mas agora será ajustado com o campo `behavior`.
- **Objetivo**:
  - Configurar o `behavior` no `hpa.yaml` para otimizar as janelas de estabilização, tornando o **scale up** mais rápido e o **scale down** mais controlado.
  - Testar a nova configuração simulando um pico de memória.

## Atualização do Arquivo `hpa.yaml` com Behavior
- **Motivação**:
  - O **scale up** deve ser rápido para lidar com picos de tráfego, minimizando impactos na aplicação.
  - O **scale down** deve ser controlado para evitar remoção abrupta de réplicas, mas mais rápido que o padrão (300 segundos).
  - O campo `behavior` na API `autoscaling/v2` permite personalizar essas janelas de estabilização.
- **Novo Arquivo `hpa.yaml`**:
  ```yaml
  apiVersion: autoscaling/v2
  kind: HorizontalPodAutoscaler
  metadata:
    name: widget-server-hpa
    namespace: widget
  spec:
    scaleTargetRef:
      apiVersion: apps/v1
      kind: Deployment
      name: widget-server
    minReplicas: 3
    maxReplicas: 8
    metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 75
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: 70
    behavior:
      scaleDown:
        stabilizationWindowSeconds: 30
        policies:
        - type: Pods
          value: 2
          periodSeconds: 15
        - type: Percent
          value: 20
          periodSeconds: 30
        selectPolicy: Max
      scaleUp:
        stabilizationWindowSeconds: 5
        policies:
        - type: Percent
          value: 50
          periodSeconds: 5
  ```
- **Detalhes**:
  - **`spec.metrics`**: Mantém as métricas de CPU (75%) e memória (70%), iguais à configuração anterior.
  - **`spec.behavior`**: Nova seção para personalizar o comportamento de escalabilidade.
    - **`scaleDown`**:
      - `stabilizationWindowSeconds: 30`: Define uma janela de 30 segundos após a estabilização (métricas abaixo dos alvos) para iniciar o **downscaling**, bem mais curta que o padrão (300 segundos).
      - `policies`:
        - **Política 1**: `type: Pods`, `value: 2`, `periodSeconds: 15`
          - Remove 2 pods a cada 15 segundos após a janela de estabilização.
        - **Política 2**: `type: Percent`, `value: 20`, `periodSeconds: 30`
          - Remove 20% das réplicas a cada 30 segundos, proporcional ao número total de réplicas (ex.: 20% de 5 réplicas = 1 pod).
      - `selectPolicy: Max`: Seleciona a política mais agressiva entre `Pods` e `Percent`. Nesse caso, a política de `Pods` (2 pods a cada 15 segundos) é mais agressiva devido ao menor intervalo.
    - **`scaleUp`**:
      - `stabilizationWindowSeconds: 5`: Inicia o **scale up** após 5 segundos de métricas acima dos alvos, garantindo resposta rápida a picos.
      - `policies`:
        - **Política 1**: `type: Percent`, `value: 50`, `periodSeconds: 5`
          - Adiciona 50% do número atual de réplicas a cada 5 segundos (ex.: de 4 para 6 réplicas em 5 segundos, de 6 para 9 em mais 5 segundos, limitado a `maxReplicas: 8`).
      - **Nota**: Apenas uma política foi definida para **scale up**, eliminando a necessidade de `selectPolicy`.
- **Aplicação**: `kubectl apply -f k8s/`
  - Atualiza o HPA com as novas configurações de `behavior`.
- **Verificação**: `kubectl get hpa -n widget`
  - Confirma que o HPA está ativo, com alvos de 75% (CPU) e 70% (memória).
  - **Comando**: `kubectl describe hpa -n widget`
    - Exibe detalhes do HPA, incluindo:
      - Configurações de `behavior` (50% a cada 5 segundos para **scale up**, 2 pods a cada 15 segundos ou 20% a cada 30 segundos para **scale down**, com `Max`).
      - Eventos de escalabilidade anteriores (ex.: **scale up** de 3 para 7 réplicas devido a memória acima do alvo, **downscaling** quando métricas ficaram abaixo).

## Teste de Escalabilidade com Behavior
- **Simulação de Pico**:
  - O alvo de memória (`averageUtilization`) foi reduzido para 10% (abaixo do uso atual, ex.: 22%) para forçar um **scale up**.
  - **Comando**: `kubectl apply -f k8s/`
    - Aplica a mudança no `hpa.yaml`.
  - **Monitoramento**:
    - **Comando**: `watch kubectl get pods -n widget`
      - Observa o aumento de réplicas em tempo real.
    - **Comando**: `watch kubectl get hpa -n widget`
      - Acompanha as métricas do HPA (ex.: memória a 22% > 10%).
  - **Resultado**:
    - O HPA detecta o uso de memória acima do alvo (22% > 10%) e escala rapidamente, respeitando a janela de 5 segundos do **scale up**.
    - **Política de Scale Up**: Adiciona 50% das réplicas a cada 5 segundos (ex.: de 3 para 4,5 réplicas em 5 segundos, de 4,5 para ~7 em mais 5 segundos).
    - **Verificação**: Após ~10 segundos, o número de réplicas aumenta para 5 (limitado por arredondamentos e `maxReplicas: 8`).
    - O **scale up** foi mais rápido que na aula anterior (20% de memória), pois a janela de estabilização foi reduzida para 5 segundos e a política de 50% é agressiva.
  - **Observação**:
    - Na aula anterior, o **scale up** para 20% de memória foi mais lento, possivelmente porque o uso (22%) estava próximo do alvo, causando atrasos na detecção. Com 10%, a diferença é mais clara, e o **behavior** configurado acelera a resposta.

- **Retorno ao Estado Normal**:
  - O alvo de memória é restaurado para 70% (acima do uso atual, ex.: 22%).
  - **Comando**: `kubectl apply -f k8s/`
    - Aplica a correção no `hpa.yaml`.
  - **Resultado**:
    - O HPA detecta que o uso de memória (22%) está abaixo do alvo (70%) e inicia o **downscaling** após 30 segundos (janela de estabilização).
    - **Política de Scale Down**: Remove 2 pods a cada 15 segundos (política `Pods`, selecionada como `Max`).
    - **Verificação**: `kubectl get pods -n widget`
      - Mostra a redução de 5 para 3 réplicas em ~45 segundos (30 segundos de espera + 15 segundos para remover 2 pods).
    - O **downscaling** foi significativamente mais rápido que o padrão (300 segundos), respeitando a configuração de `behavior`.
  - **Motivação**:
    - A janela reduzida (30 segundos) e a política agressiva (2 pods a cada 15 segundos) otimizam o uso de recursos, minimizando custos com réplicas desnecessárias.

## Flexibilidade do HPA
- **Métricas**:
  - O HPA monitora CPU (75%) e memória (70%) simultaneamente, mas pode ser configurado para apenas uma métrica:
    - Ex.: Remover a métrica de memória para escalar apenas por CPU, ou vice-versa.
    - **Vantagem**: Adapta-se a casos específicos onde uma métrica é mais relevante.
  - O uso médio (`averageUtilization`) é calculado com base nos `requests` definidos no **Deployment** (ex.: 200m para CPU, 256Mi para memória por pod).
- **Behavior**:
  - O campo `behavior` é opcional. Sem ele, o HPA usa valores padrão (ex.: 300 segundos para **scale down**, menos agressivo para **scale up**).
  - Configurações personalizadas, como as definidas, oferecem controle granular para cenários críticos.
- **Eventos**:
  - **Comando**: `kubectl describe hpa -n widget`
    - Registra ações do HPA, como **scale up** (ex.: memória acima do alvo) e **scale down** (métricas abaixo do alvo).
    - Útil para depuração e monitoramento.

## Planejamento para a Próxima Aula
- **Teste de Estresse**:
  - Simular tráfego intenso na aplicação `widget-server` para validar o HPA em um cenário real.
  - Configurar um teste de carga para aumentar o uso de CPU e/ou memória, observando o comportamento do HPA.
  - **Objetivo**: Refinar configurações como `minReplicas`, `maxReplicas`, e alvos de utilização com base em dados reais, evitando estimativas imprecisas ("chutômetro").
- **Outros Tópicos**:
  - Continuar explorando **Secrets** e **Ingress** para a aplicação.
  - Integrar ferramentas de observabilidade (ex.: Prometheus, Grafana) para monitorar o HPA e métricas da aplicação.

## Limitações e Observações
- **Behavior**:
  - Configurações muito agressivas (ex.: janelas muito curtas ou políticas com valores altos) podem causar instabilidade, como **scale down** prematuro ou **scale up** excessivo.
  - A escolha de `selectPolicy: Max` prioriza a política mais agressiva, mas exige cuidado para evitar conflitos ou comportamentos indesejados.
- **Métricas Próximas ao Alvo**:
  - Quando o uso está próximo do alvo (ex.: 22% vs. 20% para memória), o HPA pode atrasar a escalabilidade devido a flutuações normais. Alvos mais distantes (ex.: 10%) tornam a detecção mais confiável.
- **Valores Padrão**:
  - Sem o campo `behavior`, o HPA usa configurações conservadoras (ex.: 300 segundos para **scale down**), adequadas para a maioria dos casos, mas menos otimizadas para cenários específicos.
- **Custo e Otimização**:
  - Réplicas excedentes aumentam custos em clusters pagos. O **downscaling** rápido (30 segundos + 2 pods a cada 15 segundos) minimiza esse impacto.
- **Ambiente Local**:
  - A configuração do **Metrics Server** com `--kubelet-insecure-tls` (definida em aulas anteriores) é aceitável para aprendizado, mas não para produção.
- **Boas Práticas**:
  - Definir janelas de estabilização curtas para **scale up** (ex.: 5 segundos) em aplicações críticas.
  - Usar políticas de **scale down** baseadas em porcentagem para maior escalabilidade (ex.: 20% adapta-se a diferentes números de réplicas).
  - Monitorar eventos do HPA (`kubectl describe hpa`) para identificar anomalias ou ajustes necessários.
  - Realizar testes de estresse para calibrar alvos de utilização e limites de réplicas.

## Conclusão
A aula aprimora o HPA `widget-server-hpa` com a API `autoscaling/v2`, adicionando o campo `behavior` para personalizar o **scale up** (50% a cada 5 segundos) e **scale down** (2 pods a cada 15 segundos ou 20% a cada 30 segundos, com `selectPolicy: Max`). O teste com um alvo de memória de 10% demonstra um **scale up** rápido (de 3 para 5 réplicas em ~10 segundos) e um **downscaling** eficiente (de 5 para 3 em ~45 segundos) ao restaurar o alvo para 70%. A configuração de `behavior` torna o HPA mais responsivo e econômico, respeitando as métricas de CPU (75%) e memória (70%). A próxima aula focará em testes de estresse para validar o HPA em cenários reais, refinando configurações e integrando observabilidade.
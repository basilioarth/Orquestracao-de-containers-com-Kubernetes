# Resumo da Aula sobre Teste de Estresse com o Horizontal Pod Autoscaler (HPA) no Kubernetes

## Introdução
A aula realiza um teste de estresse na aplicação `widget-server` para validar o comportamento do **Horizontal Pod Autoscaler (HPA)** configurado com a API `autoscaling/v2`. As configurações do **Deployment** e do HPA são ajustadas para simular um ambiente com recursos limitados (menos réplicas e menos CPU/memória), e a ferramenta **FortIO** é usada para gerar carga intensa. O teste avalia a capacidade do HPA de escalar automaticamente sob estresse, demonstrando a eficácia do `behavior` configurado na aula anterior. A aula também introduz o comando `kubectl run` para execuções imperativas e aborda boas práticas de testes de carga, finalizando com o planejamento para explorar **ConfigMaps** e **Secrets**.

## Configuração Inicial
- **Contexto**:
  - O HPA `widget-server-hpa` foi configurado na aula anterior com a API `autoscaling/v2`, escalando o **Deployment** `widget-server` com base em CPU (75%) e memória (70%), mínimo de 3 réplicas, máximo de 8, e `behavior` personalizado:
    - **Scale Up**: 50% das réplicas a cada 5 segundos.
    - **Scale Down**: 2 pods a cada 15 segundos ou 20% a cada 30 segundos (política `Max`), com janela de estabilização de 30 segundos.
  - Para o teste de estresse, o ambiente será calibrado com menos recursos para forçar a escalabilidade.
- **Objetivo**:
  - Reduzir réplicas e recursos (CPU/memória) no **Deployment** e ajustar o HPA para alvos mais baixos (60% para CPU e memória).
  - Executar um teste de carga com **FortIO** para simular tráfego intenso e observar o comportamento do HPA.
  - Avaliar a escalabilidade e refinar configurações com base em dados reais.

## Ajustes no Deployment e HPA
- **Motivação**:
  - Reduzir recursos e réplicas cria um ambiente mais restritivo, ideal para testar o HPA sob pressão.
  - Alvos de utilização mais baixos (60%) tornam o HPA mais sensível, facilitando a detecção de picos.
- **Atualização do `deployment.yaml`**:
  ```yaml
  apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: widget-server
    namespace: widget
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: widget-server
    template:
      metadata:
        labels:
          app: widget-server
      spec:
        containers:
        - name: widget-server
          image: widget-server:latest
          resources:
            requests:
              cpu: "100m"
              memory: "128Mi"
            limits:
              cpu: "200m"
              memory: "256Mi"
  ```
  - **Mudanças**:
    - `replicas: 2`: Reduz de 3 para 2 réplicas.
    - `resources.requests`:
      - CPU: de 200m para **100m**.
      - Memória: de 256Mi para **128Mi**.
    - `resources.limits`:
      - CPU: de 400m para **200m** (mantém o limite como 2x o request).
      - Memória: de 512Mi para **256Mi** (mantém o limite como 2x o request).
- **Atualização do `hpa.yaml`**:
  ```yaml
  apiVersion: autoscaling/v2
  kind: HorizontalPodAutoscaler
  metadata:
    name: widget-server-hpa
    namespace: widget
  spec:
    scaleTargetRef:
      apiVersion: apps/v1
      kind: Deployment
      name: widget-server
    minReplicas: 2
    maxReplicas: 8
    metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 60
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: 60
    behavior:
      scaleDown:
        stabilizationWindowSeconds: 30
        policies:
        - type: Pods
          value: 2
          periodSeconds: 15
        - type: Percent
          value: 20
          periodSeconds: 30
        selectPolicy: Max
      scaleUp:
        stabilizationWindowSeconds: 5
        policies:
        - type: Percent
          value: 50
          periodSeconds: 5
  ```
  - **Mudanças**:
    - `minReplicas: 2`: Alinhado com o **Deployment** (reduzido de 3).
    - `metrics`:
      - CPU: `averageUtilization` reduzido de 75% para **60%** (60m para 100m de `requests` por pod).
      - Memória: `averageUtilization` reduzido de 70% para **60%** (76.8Mi para 128Mi de `requests` por pod).
    - `behavior`: Mantém a configuração anterior (scale up de 50% a cada 5 segundos, scale down de 2 pods a cada 15 segundos ou 20% a cada 30 segundos).
- **Aplicação**:
  - **Comando**: `kubectl apply -f k8s/`
    - Aplica as mudanças nos arquivos `deployment.yaml` e `hpa.yaml`.
  - **Verificação**:
    - **Comando**: `watch kubectl get pods -n widget`
      - Confirma que o **Deployment** reduz para 2 réplicas.
    - **Comando**: `watch kubectl get hpa -n widget`
      - Mostra o HPA com alvos de 60% para CPU e memória, uso inicial de memória a ~46% (59Mi de 128Mi por pod), próximo ao limite, mas estável.
- **Observação**:
  - A memória inicial (~46%) está próxima do alvo (60%), indicando que a configuração de 128Mi pode ser insuficiente em cenários reais, sugerindo um ajuste futuro.

## Teste de Estresse com FortIO
- **Motivação**:
  - Simular tráfego intenso para forçar o uso de CPU e memória, testando a resposta do HPA.
  - Usar uma ferramenta leve e imperativa para demonstrar testes de carga sem configurações complexas.
- **Ferramenta Escolhida: FortIO**:
  - **Por que FortIO?**:
    - Simples, leve e eficiente para testes de estresse HTTP.
    - Pode ser executada como container no Kubernetes, sem necessidade de instalação local.
    - Alternativas mencionadas: **Vegeta**, **Locust**, **K6** (Grafana Labs, open-source ou cloud).
  - **Imagem**: `fortio/fortio:latest` (disponível no Docker Hub).
    - **Boa Prática**: Usar versões específicas (ex.: `fortio/fortio:1.69.5`) em produção para evitar surpresas com `latest`.
- **Execução Imperativa com `kubectl run`**:
  - **Comando**:
    ```bash
    kubectl run fortio --it --rm --image=fortio/fortio:latest --namespace=widget -- load -qps 5000 -t 60s -c 20 http://widget-server.widget.svc.cluster.local/real
    ```
  - **Detalhes**:
    - `run fortio`: Cria um pod temporário chamado `fortio`.
    - `--it`: Executa interativamente (permite ver a saída em tempo real).
    - `--rm`: Remove o pod automaticamente após a execução (similar a um **Job**).
    - `--image=fortio/fortio:latest`: Usa a imagem do FortIO.
    - `--namespace=widget`: Executa no namespace `widget`, garantindo acesso direto ao serviço `widget-server`.
    - `load`: Subcomando do FortIO para gerar carga HTTP.
      - `-qps 5000`: 5.000 queries por segundo (QPS).
      - `-t 60s`: Duração de 60 segundos.
      - `-c 20`: 20 conexões simultâneas (threads).
      - `http://widget-server.widget.svc.cluster.local/real`: Endereço do serviço `widget-server` no namespace `widget`, acessando o endpoint `/real`.
    - **Endereço DNS**:
      - No mesmo namespace (`widget`), o serviço é acessado como `widget-server`.
      - Em outro namespace (ex.: `default`), seria `widget-server.widget.svc.cluster.local`.
  - **Nota**:
    - `kubectl run` é útil para execuções rápidas, mas não é recomendado para produção (configurações declarativas com YAML são preferíveis).
    - O uso de `--rm` evita pods órfãos, mantendo o cluster limpo.
- **Monitoramento**:
  - **Comando**: `watch kubectl get pods -n widget`
    - Observa o número de réplicas em tempo real.
  - **Comando**: `watch kubectl get hpa -n widget`
    - Acompanha o uso de CPU e memória e as ações do HPA.

## Resultados do Teste de Estresse
- **Execução**:
  - O FortIO gerou ~100.000 requisições em 60 segundos (5.000 QPS × 20 conexões), corrigindo o cálculo inicial da aula (não 300.000, mas ~100.000 requisições).
  - O pod `fortio` foi criado no namespace `widget`, executou o teste por 60 segundos e foi removido automaticamente (`--rm`).
- **Comportamento do HPA**:
  - **Início**:
    - Uso inicial: ~46% de memória (59Mi de 128Mi por pod), CPU baixa.
    - O teste começou a aumentar o uso de CPU significativamente, com memória permanecendo estável inicialmente.
  - **Pico**:
    - CPU atingiu níveis altos (não especificados, mas suficientes para ultrapassar 60% ou 60m por pod).
    - Memória subiu, mas permaneceu abaixo do alvo de 60% (76.8Mi por pod).
    - O HPA detectou o pico de CPU e iniciou o **scale up**:
      - **Política**: 50% das réplicas a cada 5 segundos (janela de estabilização de 5 segundos).
      - Resultado: Aumentou de 2 para **6 réplicas** durante o teste.
    - **Observação**: A escalabilidade foi considerada tardia, pois o teste estava quase terminando (~60 segundos), sugerindo que o HPA demorou a responder ao pico de CPU.
  - **Pós-Teste**:
    - Após o término do teste (pod `fortio` removido), o uso de CPU e memória caiu drasticamente (memória para ~1%).
    - O HPA iniciou o **scale down**:
      - **Política**: 2 pods a cada 15 segundos (política `Pods` selecionada como `Max`, janela de 30 segundos).
      - Resultado: Reduziu de 6 para **2 réplicas** (mínimo configurado) em poucos minutos.
    - O `behavior` configurado funcionou bem, com **scale up** rápido (5 segundos) e **scale down** eficiente (30 segundos + 15 segundos por remoção).
- **Métricas do FortIO**:
  - **Total**: ~100.000 requisições processadas em 60 segundos (não 300.000, corrigindo o erro inicial).
  - **Sucesso**: Todas as requisições retornaram status HTTP 200 (sem erros).
  - **Latência Média**: ~3.400 ms (abaixo do alvo de 5.000 QPS, indicando que a aplicação não atingiu o desempenho esperado).
  - **Percentis**: P95 e P99 reportados, mas não detalhados (indicadores de latência em cenários de alta carga).
  - **Desempenho**: A aplicação lidou com ~1.667 QPS reais (100.000 requisições ÷ 60 segundos), abaixo dos 5.000 QPS almejados, sugerindo limitação de recursos.
- **Observações**:
  - A configuração inicial (100m CPU, 128Mi memória, 2 réplicas) foi insuficiente para suportar 5.000 QPS, justificando a escalabilidade para 6 réplicas.
  - O **scale up** tardio indica que o alvo de CPU (60%) ou a janela de 5 segundos pode precisar de ajustes (ex.: alvo mais baixo ou janela menor).
  - A memória permaneceu estável (~46%), sugerindo que o endpoint `/real` é mais CPU-intensivo.

## Análise e Calibração
- **Resultados**:
  - O HPA respondeu ao pico de CPU, escalando para 6 réplicas, mas a resposta tardia limitou o desempenho (1.667 QPS vs. 5.000 QPS almejados).
  - O **scale down** foi eficiente, retornando a 2 réplicas rapidamente, otimizando recursos.
  - A configuração de memória (128Mi) estava no limite (~46% em repouso), sugerindo um aumento para ~256Mi para maior estabilidade.
- **Calibração**:
  - **CPU**: Aumentar `requests` para 200m (como na configuração original) e ajustar o alvo do HPA para ~50% (50m) para detectar picos mais cedo.
  - **Memória**: Aumentar `requests` para 256Mi e manter o alvo em 60% (153.6Mi) para evitar gargalos.
  - **Réplicas**: Manter `minReplicas: 2`, mas considerar `maxReplicas: 10` para suportar picos maiores.
  - **Behavior**: A janela de 5 segundos para **scale up** foi eficaz, mas pode ser reduzida para 3 segundos em cenários críticos.
- **Boas Práticas**:
  - **Gordura nos Recursos**: Configurar `requests` e `limits` com margem (ex.: 20-30% acima do uso observado) para evitar throttles.
  - **Testes Iterativos**: Simular tráfegos realistas (ex.: 1.000 QPS para cenários comuns) e ajustar configurações com base em percentis (P95, P99).
  - **Monitoramento**: Usar ferramentas como Prometheus/Grafana para analisar CPU, memória e latência em tempo real.
  - **Estimativas Iniciais**: Para produtos novos, configurar recursos "para cima" (ex.: 3 réplicas, 200m CPU, 256Mi memória) e refinar com dados de produção.

## Observações sobre Kubernetes
- **DNS Interno**:
  - No mesmo namespace (`widget`), o serviço é acessado como `widget-server` ou `widget-server.widget.svc.cluster.local`.
  - Em outro namespace (ex.: `default`), deve-se usar `widget-server.widget.svc.cluster.local`.
  - O pod `fortio` no namespace `widget` acessou o serviço diretamente, simplificando a configuração.
- **kubectl run**:
  - Útil para testes rápidos, mas não recomendado para produção (YAMLs são mais rastreáveis e reprodutíveis).
  - A flag `--rm` garante limpeza automática, ideal para testes temporários.
- **Namespace**:
  - Executar o FortIO no namespace `widget` facilitou o acesso ao serviço `widget-server`.
  - Alternativamente, usar o namespace `default` exigiria o endereço DNS completo (`widget-server.widget.svc.cluster.local`).

## Planejamento para a Próxima Aula
- **ConfigMaps e Secrets**:
  - Explorar a criação e uso de **ConfigMaps** para gerenciar configurações da aplicação (ex.: variáveis de ambiente, arquivos de configuração).
  - Configurar **Secrets** para armazenar dados sensíveis (ex.: chaves API, senhas) e injetá-los na aplicação `widget-server`.
  - Discutir boas práticas para gerenciamento de `env` e segurança no Kubernetes.
- **Outros Tópicos**:
  - Continuar refinando o **Ingress** para a aplicação.
  - Integrar observabilidade (ex.: Prometheus, Grafana) para monitorar métricas do HPA e da aplicação.
  - Realizar testes adicionais de carga para calibrar o **Deployment** e o HPA em cenários variados.

## Limitações e Observações
- **Recursos Insuficientes**:
  - A configuração inicial (100m CPU, 128Mi memória, 2 réplicas) foi subdimensionada para 5.000 QPS, resultando em latência alta (~3.400 ms) e escalabilidade tardia.
  - Aumentar `requests` e `limits` (ex.: 200m CPU, 256Mi memória) e ajustar alvos do HPA (ex.: 50%) pode melhorar o desempenho.
- **Escalabilidade Tardia**:
  - O **scale up** demorou devido ao pico rápido de CPU e à janela de 5 segundos. Reduzir a janela para 3 segundos ou o alvo para 50% pode acelerar a resposta.
- **FortIO**:
  - Eficiente para testes simples, mas ferramentas como **K6** ou **Locust** oferecem mais recursos para cenários complexos (ex.: scripts personalizados, relatórios detalhados).
  - A versão `latest` foi usada por simplicidade, mas versões específicas (ex.: `1.69.5`) são recomendadas em produção.
- **kubectl run**:
  - Prático para testes, mas YAMLs são preferíveis para rastreabilidade e automação.
  - A flag `--rm` evitou pods órfãos, mas exige cuidado para não esquecer pods em execuções manuais.
- **Custo e Otimização**:
  - O **scale down** rápido (30 segundos + 2 pods a cada 15 segundos) otimizou recursos, mas réplicas temporárias (6 durante o teste) aumentam custos em clusters pagos.
  - Configurações realistas (baseadas em testes) minimizam réplicas desnecessárias.
- **Ambiente Local**:
  - O **Metrics Server** com `--kubelet-insecure-tls` (configurado anteriormente) é aceitável para aprendizado, mas não para produção.
- **Boas Práticas**:
  - Realizar testes de carga com tráfegos realistas (ex.: 1.000-2.000 QPS) para calibrar recursos.
  - Configurar alvos de utilização entre 50-60% para CPU/memória para resposta rápida a picos.
  - Monitorar percentis (P95, P99) para garantir desempenho em cenários de alta carga.
  - Usar versões específicas de imagens para evitar instabilidades.
  - Documentar configurações em YAML para reprodutibilidade.

## Conclusão
A aula testou o HPA da aplicação `widget-server` sob estresse, ajustando o **Deployment** para 2 réplicas, 100m CPU, 128Mi memória, e o HPA para alvos de 60% (CPU/memória). O teste com **FortIO** (5.000 QPS, 20 conexões, 60 segundos) gerou ~100.000 requisições, aumentando o uso de CPU e escalando de 2 para 6 réplicas, mas com resposta tardia. O **scale down** foi eficiente, retornando a 2 réplicas após o teste. A configuração de `behavior` (scale up de 50% a cada 5 segundos, scale down de 2 pods a cada 15 segundos) funcionou bem, mas a calibração revelou a necessidade de mais recursos (ex.: 200m CPU, 256Mi memória) e alvos mais sensíveis (ex.: 50%). A próxima aula explorará **ConfigMaps** e **Secrets**, além de continuar o refinamento da aplicação com observabilidade e testes adicionais.
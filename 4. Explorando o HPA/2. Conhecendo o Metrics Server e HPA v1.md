# Resumo da Aula sobre Configuração do Metrics Server e Horizontal Pod Autoscaler (HPA) no Kubernetes

## Introdução
A aula aborda a configuração inicial do **Horizontal Pod Autoscaler (HPA)** para a aplicação `widget-server`, começando pela instalação do **Metrics Server**, um componente essencial para fornecer métricas de CPU e memória ao HPA. A aplicação, configurada com um **Deployment** de 3 réplicas (reduzido de 5), é preparada para escalabilidade automática. A aula detalha a instalação manual do **Metrics Server** em um cluster local (usando Kind), a criação de um arquivo `hpa.yaml` com a API legada (`autoscaling/v1`), e a introdução à API moderna (`autoscaling/v2`), que será explorada na próxima aula. O foco é na escalabilidade horizontal baseada em CPU, com menção a métricas customizadas e ferramentas como **KEDA** para escalas baseadas em eventos.

## Configuração Inicial do Cluster
- **Ajuste do Deployment**:
  - O número de réplicas no `deployment.yaml` foi reduzido de 5 para 3 para simplificar o exemplo.
  - **Comando**: `kubectl apply -f k8s/`
    - Reaplica a configuração na pasta `k8s`, atualizando o **Deployment** `widget-server` no namespace `widget`.
  - **Verificação**: `kubectl get pods -n widget`
    - Confirma que 3 pods estão em execução, conforme definido no **Deployment**.

## Instalação do Metrics Server
- **O que é o Metrics Server?**
  - Um componente do Kubernetes que coleta métricas de uso de CPU e memória dos pods a cada 10 segundos, em um loop fechado.
  - Essencial para o funcionamento do HPA, pois fornece as métricas necessárias para decisões de escalabilidade.
  - **Nota**: Em clusters gerenciados (ex.: AWS EKS, GKE), o **Metrics Server** geralmente é pré-instalado. Em clusters locais (ex.: Kind), requer instalação manual.

- **Instalação Manual**:
  - **Fonte**: A última release do **Metrics Server** (v0.8, julho de 2025) é obtida de `https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml`.
  - **Motivação**: Em vez de aplicar diretamente o YAML remoto (`kubectl apply -f <URL>`), o arquivo é baixado para maior controle e personalização.
  - **Passos**:
    1. **Download**: `wget <URL> -O metrics-server.yaml`
       - Baixa o arquivo `components.yaml` e renomeia para `metrics-server.yaml`, armazenado na pasta `infra` (usada para configurações de cluster, como criação do Kind e namespace).
    2. **Ajuste para Ambiente Local**:
       - O **Metrics Server** requer um certificado assinado por uma Certificate Authority (CA), disponível em clusters gerenciados, mas ausente em clusters locais com Kind.
       - **Solução**: Adicionar o argumento `--kubelet-insecure-tls` ao **Deployment** do **Metrics Server** no arquivo `metrics-server.yaml` para desabilitar a validação de certificados TLS.
         ```yaml
         spec:
           template:
             spec:
               containers:
               - name: metrics-server
                 args:
                 - --kubelet-insecure-tls
         ```
       - **Aviso**: Essa configuração é aceitável apenas em ambientes locais, não em produção, devido a riscos de segurança.
    3. **Aplicação**: `kubectl apply -f infra/metrics-server.yaml`
       - Instala o **Metrics Server** no namespace `kube-system`, criando recursos como **ServiceAccount**, **ClusterRole**, **RoleBinding**, **Service**, e **Deployment**.
  - **Verificação**:
    - **Comando**: `kubectl get pods -n kube-system`
      - Confirma que o pod do **Metrics Server** está em execução (status `1/1`).
    - **Comando**: `kubectl logs <metrics-server-pod-name> -n kube-system`
      - Permite inspecionar os logs para confirmar que o serviço está ativo e sincronizado.
    - **Nota**: Sem o argumento `--kubelet-insecure-tls`, o pod falharia na inicialização devido à ausência de um CA válido.

- **Estrutura do Metrics Server**:
  - **Namespace**: `kube-system` (padrão para componentes do sistema).
  - **Recursos Criados**:
    - **Deployment**: Executa o container do **Metrics Server** (imagem: `k8s.gcr.io/metrics-server/metrics-server`).
    - **Service**: Expõe o **Metrics Server** internamente para comunicação com o HPA.
    - **ServiceAccount** e **RBAC**: Garantem permissões para coletar métricas dos nós e pods.
  - **Funcionamento**: Faz scraping de métricas do **Kubelet** (agente nos nós) a cada 10 segundos, fornecendo dados ao HPA.

## Introdução ao HPA e Configuração Inicial
- **O que é o HPA?**
  - O **Horizontal Pod Autoscaler** ajusta automaticamente o número de réplicas de um **Deployment** ou **ReplicaSet** com base em métricas, como uso de CPU ou memória.
  - **Dependência**: Requer o **Metrics Server** para obter métricas de CPU/memória. Sem ele, o HPA cria, mas exibe métricas como `unknown`.
  - **Alternativas para Escalabilidade**:
    - **Métricas Customizadas**: O HPA (especialmente na API `autoscaling/v2`) suporta métricas além de CPU/memória, como consumo de filas (ex.: Kafka, RabbitMQ).
    - **KEDA (Kubernetes Event-Driven Autoscaling)**:
      - Um **Custom Resource Definition (CRD)** que estende a API do Kubernetes para escalar com base em eventos.
      - Suporta escaladores para Kafka, ActiveMQ, RabbitMQ, AWS SQS, entre outros.
      - **Nota**: Não será abordado em detalhes, pois foge do escopo full stack, mas é mencionado como opção para escalas baseadas em eventos.
    - **Escalabilidade Vertical**: Ajusta os recursos (CPU/memória) de pods existentes, menos comum devido à preferência por redundância com mais pods menores.

- **Criação do Arquivo `hpa.yaml`**:
  - **Localização**: Arquivo criado na pasta `k8s` (ao lado de `deployment.yaml` e `service.yaml`), pois o HPA é específico da aplicação, não do cluster.
  - **Versão Legada (`autoscaling/v1`)**:
    - Usada inicialmente para ilustrar configurações comuns em clusters mais antigos.
    - **Conteúdo do `hpa.yaml`**:
      ```yaml
      apiVersion: autoscaling/v1
      kind: HorizontalPodAutoscaler
      metadata:
        name: widget-server-hpa
        namespace: widget
      spec:
        scaleTargetRef:
          apiVersion: apps/v1
          kind: Deployment
          name: widget-server
        minReplicas: 3
        maxReplicas: 8
        targetCPUUtilizationPercentage: 75
      ```
    - **Detalhes**:
      - **`apiVersion: autoscaling/v1`**: API legada, limitada a métricas de CPU.
      - **`kind: HorizontalPodAutoscaler`**: Define o recurso HPA.
      - **`metadata.name: widget-server-hpa`**: Nome do HPA, com convenção `-hpa`.
      - **`metadata.namespace: widget`**: Aloca o HPA no mesmo namespace da aplicação.
      - **`spec.scaleTargetRef`**: Referencia o **Deployment** `widget-server` (API `apps/v1`) a ser escalado.
      - **`spec.minReplicas: 3`**: Mínimo de réplicas, alinhado com o **Deployment**.
      - **`spec.maxReplicas: 8`**: Máximo de réplicas, limitando a escalabilidade para evitar sobrecarga no cluster.
      - **`spec.targetCPUUtilizationPercentage: 75`**: Alvo de uso de CPU (75% do `requests` de CPU por pod, ou seja, 150m para 200m configurados).
        - **Dica**: Usar 70-80% evita escalas tardias em picos de tráfego, permitindo que o HPA aja antes que o cluster fique sobrecarregado. 100% pode comprometer a aplicação antes da escala.
  - **Aplicação**: `kubectl apply -f k8s/`
    - Cria o HPA no namespace `widget`.

- **Verificação do HPA**:
  - **Comando**: `kubectl get hpa -n widget`
    - Exibe o HPA `widget-server-hpa`:
      - **Referência**: `Deployment/widget-server`.
      - **Mínimo/Máximo**: 3/8 réplicas.
      - **Uso Atual**: 0% (sem tráfego na aplicação).
      - **Alvo**: 75% de uso de CPU.
  - **Nota**: Inicialmente, o uso pode aparecer como `unknown` até que o **Metrics Server** sincronize as métricas (após alguns segundos).
  - **Teste de Falha**:
    - Criar o HPA sem o **Metrics Server** resulta em métricas `unknown`, pois o HPA não consegue coletar dados de CPU/memória.
    - Com o **Metrics Server** instalado, as métricas são exibidas corretamente (ex.: 0%).

- **Limitações da API `autoscaling/v1`**:
  - Suporta apenas escalabilidade baseada em CPU, não em memória ou métricas customizadas.
  - Comum em clusters antigos, mas menos flexível que a API `autoscaling/v2`.

## Planejamento para a Próxima Aula
- **API Moderna (`autoscaling/v2`)**:
  - Substituir o `hpa.yaml` pela versão usando `autoscaling/v2`, que suporta:
    - Escalabilidade por CPU e memória.
    - Métricas customizadas (ex.: consumo de filas, latência), embora não sejam abordadas em detalhes.
  - Comparar diferenças com a API `autoscaling/v1`.
- **Comportamento do HPA**:
  - Explorar janelas de estabilização (ex.: tempo para escalar/desescalar) e configurações avançadas.
- **Testes Práticos**:
  - Simular tráfego para validar a escalabilidade (ex.: aumentar o uso de CPU acima de 75% para disparar a criação de réplicas).
- **Outros Tópicos**:
  - Continuar a explorar **Secrets** e **Ingress**.
  - Mencionar ferramentas de observabilidade (ex.: Prometheus, Grafana) para monitorar o HPA.

## Limitações e Observações
- **Metrics Server**:
  - Essencial para o HPA, mas requer ajustes em ambientes locais (ex.: `--kubelet-insecure-tls`).
  - Em produção, deve ser configurado com certificados TLS válidos para segurança.
- **API `autoscaling/v1`**:
  - Limitada a CPU, inadequada para cenários complexos (ex.: escalas baseadas em memória ou eventos).
  - Ainda comum em clusters legados, justificando sua introdução na aula.
- **Escalabilidade Vertical**:
  - Menos usada devido à preferência por redundância com mais pods menores.
  - Requer ajustes nos `requests`/`limits` dos pods, aumentando a complexidade.
- **KEDA**:
  - Alternativa poderosa para escalas baseadas em eventos, mas fora do escopo full stack.
  - Requer instalação de um CRD e configuração específica para cada escalador (ex.: Kafka, SQS).
- **Boas Práticas**:
  - Definir `targetCPUUtilizationPercentage` entre 70-80% para evitar atrasos na escalabilidade.
  - Monitorar o `maxReplicas` para detectar anomalias (ex.: atingir o limite máximo indica problemas na aplicação ou cluster).
  - Usar namespaces consistentes (`widget` para aplicação, `kube-system` para infra) para organização.
- **Redundância**:
  - Manter mais réplicas com recursos menores aumenta a resiliência, alinhando-se à filosofia do HPA.
- **Ambiente Local**:
  - Configurações como `--kubelet-insecure-tls` são aceitáveis para aprendizado, mas não para produção.

## Conclusão
A aula configura o **Metrics Server** em um cluster local (Kind), ajustando-o para operar sem validação TLS, e cria um HPA inicial com a API legada (`autoscaling/v1`) para escalar o **Deployment** `widget-server` com base em CPU (alvo: 75%, mínimo: 3 réplicas, máximo: 8). O **Metrics Server** é essencial para fornecer métricas, enquanto o HPA automatiza a escalabilidade horizontal, evitando ajustes manuais. A API `autoscaling/v1` é limitada, mas comum em clusters antigos, justificando sua introdução. A próxima aula migrará para a API `autoscaling/v2`, explorando escalabilidade por memória e comportamentos avançados do HPA. A aula também menciona alternativas como **KEDA** e escalabilidade vertical, reforçando boas práticas para redundância e monitoramento.